# ClassificaÃ§Ã£o de Sentimentos em AvaliaÃ§Ãµes de Produtos com NLP

---

### ğŸ¯ Objetivo do Projeto

O objetivo deste projeto Ã© aplicar tÃ©cnicas de **Processamento de Linguagem Natural (NLP)** para analisar e classificar sentimentos de avaliaÃ§Ãµes de produtos. O modelo aprenderÃ¡ a identificar se um review Ã© **positivo ou negativo** , permitindo que empresas compreendam melhor o que os clientes estÃ£o dizendo e priorizem aÃ§Ãµes de melhoria.

---

### âš™ï¸Criando env

```
conda create --name cases_data_science python=3.10
conda activate cases_data_science
```

Se precisar deletar env

```
conda remove --name cases_data_science --all
```

Exportar notebook para md

```
jupyter nbconvert notebook.ipynb --to markdown --no-input

```

---

### ğŸ“Š Fonte e ExplicaÃ§Ã£o dos Dados

- **Fonte:** [Amazon Fine Food Reviews â€“ Kaggle](https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews)
- **DescriÃ§Ã£o:**

  ContÃ©m mais de 500.000 avaliaÃ§Ãµes de alimentos da Amazon, incluindo:

  - `Score`: avaliaÃ§Ã£o de 1 a 5 estrelas
  - `Text`: o conteÃºdo textual da avaliaÃ§Ã£o
  - `Summary`: resumo da avaliaÃ§Ã£o
  - `Time`, `UserId`, `ProductId`

Para o projeto, o score serÃ¡ **binarizado** (1-2 = negativo, 4-5 = positivo; 3 serÃ¡ removido).

---

### ğŸ“ Estrutura de Pastas e Arquivos

```
sentiment-analysis-nlp-product-reviews/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                     # Dados originais baixados do Kaggle
â”‚   â””â”€â”€ processed/               # Dados limpos e balanceados
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb             # AnÃ¡lise exploratÃ³ria e visualizaÃ§Ãµes
â”‚   â”œâ”€â”€ 02_preprocessing.ipynb   # Limpeza de texto e vetorizaÃ§Ã£o
â”‚   â”œâ”€â”€ 03_modeling.ipynb        # Modelos de classificaÃ§Ã£o (LogReg, Naive Bayes)
â”‚   â”œâ”€â”€ 04_evaluation.ipynb      # MÃ©tricas, matriz de confusÃ£o e interpretaÃ§Ã£o
â”‚
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ figures/                 # GrÃ¡ficos de palavras, nuvens, resultados
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

### ğŸ” Etapas do Processo

1. **Coleta e Filtragem dos Dados**
   - Apenas reviews com score 1, 2, 4 ou 5
   - CriaÃ§Ã£o da coluna `sentiment`: positivo (1) ou negativo (0)
2. **Tratamento e VetorizaÃ§Ã£o**
   - Limpeza de texto (remoÃ§Ã£o de pontuaÃ§Ã£o, stopwords, etc.)
   - VetorizaÃ§Ã£o com TF-IDF ou CountVectorizer
   - Alternativamente, embeddings como Word2Vec ou BERT (extra)
3. **AnÃ¡lise ExploratÃ³ria**
   - DistribuiÃ§Ã£o dos sentimentos
   - Nuvem de palavras por sentimento
   - Palavras mais comuns em reviews positivos/negativos
4. **Modelagem**
   - Modelos base: Logistic Regression, Naive Bayes
   - MÃ©tricas: AcurÃ¡cia, F1-score, ROC-AUC
5. **InterpretaÃ§Ã£o e VisualizaÃ§Ã£o**
   - Matriz de confusÃ£o
   - Exemplos de frases mal classificadas

---

### âš™ï¸ Como Executar Localmente

1. Clone o repositÃ³rio:

```
git clone https://github.com/seuusuario/sentiment-analysis-nlp-product-reviews.git
cd sentiment-analysis-nlp-product-reviews
```

2. Crie um ambiente virtual (opcional) e instale as dependÃªncias:

```
pip install -r requirements.txt
```

3. Inicie os notebooks:
   ```
   jupyter notebook
   ```

Execute os notebooks em ordem para visualizar todo o pipeline.

---

### ğŸ“Š Salvar grÃ¡ficos

Plotly precisa da biblioteca **kaleido** para exportar grÃ¡ficos como imagem:

```
pip install -U kaleido
```

---

## âœ… Resultados

### ğŸ“Š DistribuiÃ§Ã£o dos Sentimentos

Antes de aplicar modelos de classificaÃ§Ã£o, foi analisada a distribuiÃ§Ã£o dos sentimentos no conjunto de dados. O grÃ¡fico abaixo mostra a quantidade de avaliaÃ§Ãµes rotuladas como:

- `0` â†’ **Negativas**
- `1` â†’ **Positivas**

<img src="./reports/figures/count_sentimentos.png" alt="DistribuiÃ§Ã£o de Sentimentos" width="500"/>

Essa visualizaÃ§Ã£o Ã© importante para verificar se os dados estÃ£o balanceados ou se hÃ¡ predominÃ¢ncia de um dos sentimentos, o que pode afetar o desempenho dos modelos de aprendizado.

---

### ğŸ’¬ AnÃ¡lise de Sentimentos â€“ Wordclouds

Para entender melhor os principais termos mencionados nas avaliaÃ§Ãµes dos clientes, foram geradas duas nuvens de palavras ( **wordclouds** ), separando comentÃ¡rios positivos e negativos.

- A nuvem Ã  esquerda mostra os termos mais frequentes em **avaliaÃ§Ãµes positivas** .
- A nuvem Ã  direita mostra os termos recorrentes em **avaliaÃ§Ãµes negativas** .

Essas visualizaÃ§Ãµes ajudam a identificar rapidamente os **temas mais valorizados** e **principais pontos de insatisfaÃ§Ã£o** entre os consumidores.
![wordcloud_sentimentos](./reports/figures/wordcloud_sentimentos.png)

---

## ğŸ“Š AvaliaÃ§Ã£o dos Modelos de ClassificaÃ§Ã£o de Sentimentos

Neste projeto, aplicamos **tÃ©cnicas de Processamento de Linguagem Natural (NLP)** para classificar automaticamente avaliaÃ§Ãµes de produtos da Amazon como **positivas ou negativas** . O objetivo principal foi desenvolver modelos capazes de interpretar textos e fornecer insights valiosos para empresas melhorarem seus produtos e serviÃ§os com base nas opiniÃµes dos clientes.

---

### âš™ï¸ Modelos Testados

Foram avaliados dois algoritmos supervisionados clÃ¡ssicos:

- **RegressÃ£o LogÃ­stica**
- **Naive Bayes Multinomial**

---

### ğŸ“Œ Comparativo de Desempenho

| Modelo                  | AcurÃ¡cia | Precision (Pos.) | Recall (Pos.) | F1-score (Pos.) | AUC  |
| ----------------------- | -------- | ---------------- | ------------- | --------------- | ---- |
| **RegressÃ£o LogÃ­stica** | 0.88     | 0.87             | 0.99          | 0.93            | 0.93 |
| **Naive Bayes**         | 0.84     | 0.84             | 1.00          | 0.91            | 0.91 |

**ObservaÃ§Ãµes:**

- A **RegressÃ£o LogÃ­stica** apresentou desempenho superior no geral, com melhor equilÃ­brio entre precisÃ£o e recall, especialmente para a classe negativa.
- O **Naive Bayes** teve recall perfeito (1.00) para a classe positiva, mas praticamente ignorou os exemplos negativos, classificando-os incorretamente (apenas 5% de recall para classe negativa).

---

### ğŸ“‰ Problema de Desbalanceamento

A anÃ¡lise das mÃ©tricas revelou um desequilÃ­brio na distribuiÃ§Ã£o das classes, com a maioria das avaliaÃ§Ãµes sendo **positivas** . Isso impacta o desempenho dos modelos, especialmente na identificaÃ§Ã£o correta de avaliaÃ§Ãµes negativas.

---

### ğŸ“· GrÃ¡ficos de AvaliaÃ§Ã£o

#### ğŸ”¹ Matriz de ConfusÃ£o â€“ RegressÃ£o LogÃ­stica

Mostra que o modelo tem **alta taxa de acerto para avaliaÃ§Ãµes positivas** , mas comete erros ao prever avaliaÃ§Ãµes negativas.

<img src="./reports/figures/ConfusionMatrix_logreg.png" alt="Matriz de ConfusÃ£o" width="500"/>
<img src="./reports/figures/ConfusionMatrix_logreg_norm.png" alt="Matriz de ConfusÃ£o Normalizada" width="500"/>

---

#### ğŸ”¹ Curva ROC â€“ RegressÃ£o LogÃ­stica

Exibe boa capacidade discriminativa com AUC de **0.93** , indicando que o modelo consegue separar bem as duas classes.

<img src="./reports/figures/roc_curve.png" alt="Curva ROC" width="500"/>

---

#### ğŸ”¹ Curva Precision-Recall

Alta precisÃ£o e recall, especialmente Ãºtil para dados desbalanceados como neste caso. A mÃ©dia da precisÃ£o Ã© **0.98** .

<img src="./reports/figures/precision_recall_curve.png" alt="Curva PrecisÃ£o e Recall" width="500"/>

---

### âœ… ConclusÃ£o

A **RegressÃ£o LogÃ­stica** demonstrou ser o modelo mais adequado para esta tarefa, entregando alta **acurÃ¡cia (0.88)** e **AUC (0.93)** . Apesar do desbalanceamento entre classes, o modelo conseguiu aprender bem o padrÃ£o das avaliaÃ§Ãµes positivas e mostrou-se razoÃ¡vel nas negativas.

Futuramente, pode-se:

- Utilizar **tÃ©cnicas de balanceamento** (como SMOTE)
- Explorar **modelos mais robustos** (como Random Forest ou BERT)
